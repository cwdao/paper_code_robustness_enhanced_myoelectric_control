{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPGAN_t03_dataprocess\n",
    "与t02,t03的处理略有区别，因此单开一文档，以免混淆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "import scipy.io as scio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载mat文件，转成numpy储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是mat转numpy用的\n",
    "# save(DataSegmentPathandName_X,'ktr_X_4c',...\n",
    "#     'ktr_X_6c','ktr_X_8c','ktr_X_10c',...\n",
    "#     'ktr_X_12c','ktr_X_16c','ktr_X_20c',...\n",
    "#     'ktr_Y_4c','ktr_Y_6c','ktr_Y_8c','ktr_Y_10c',...\n",
    "#     'ktr_Y_12c','ktr_Y_16c','ktr_Y_20c',...\n",
    "#     'kte_X_4c','kte_X_6c','kte_X_8c','kte_X_10c',...\n",
    "#     'kte_X_12c','kte_X_16c','kte_X_20c',...\n",
    "#     'kte_Y_4c','kte_Y_6c','kte_Y_8c','kte_Y_10c',...\n",
    "#     'kte_Y_12c','kte_Y_16c','kte_Y_20c',...\n",
    "#     'val_X_4c','val_Y_4c','dte_X_4c','dte_Y_4c',...\n",
    "#     'val_X_6c','val_Y_6c','dte_X_6c','dte_Y_6c',...\n",
    "#     'val_X_8c','val_Y_8c','dte_X_8c','dte_Y_8c',...\n",
    "#     'val_X_10c','val_Y_10c','dte_X_10c','dte_Y_10c',...\n",
    "#     'val_X_12c','val_Y_12c','dte_X_12c','dte_Y_12c',...\n",
    "#     'val_X_16c','val_Y_16c','dte_X_16c','dte_Y_16c',...\n",
    "#     'val_X_20c','val_Y_20c','dte_X_20c','dte_Y_20c');\n",
    "datas = scio.loadmat('../../data/nina_db1/t03.2/s4/Fopgs4_diffratio_07_11_22.mat')\n",
    "# 样本\n",
    "# 已知类训练集\n",
    "ktr_X_4c = np.transpose(datas['ktr_X_4c'],[3,2,0,1])\n",
    "ktr_X_6c = np.transpose(datas['ktr_X_6c'],[3,2,0,1])\n",
    "ktr_X_8c = np.transpose(datas['ktr_X_8c'],[3,2,0,1])\n",
    "ktr_X_10c = np.transpose(datas['ktr_X_10c'],[3,2,0,1])\n",
    "ktr_X_12c = np.transpose(datas['ktr_X_12c'],[3,2,0,1])\n",
    "ktr_X_16c = np.transpose(datas['ktr_X_16c'],[3,2,0,1])\n",
    "ktr_X_20c = np.transpose(datas['ktr_X_20c'],[3,2,0,1])\n",
    "# 已知类测试集\n",
    "kte_X_4c = np.transpose(datas['kte_X_4c'],[3,2,0,1])\n",
    "kte_X_6c = np.transpose(datas['kte_X_6c'],[3,2,0,1])\n",
    "kte_X_8c = np.transpose(datas['kte_X_8c'],[3,2,0,1])\n",
    "kte_X_10c = np.transpose(datas['kte_X_10c'],[3,2,0,1])\n",
    "kte_X_12c = np.transpose(datas['kte_X_12c'],[3,2,0,1])\n",
    "kte_X_16c = np.transpose(datas['kte_X_16c'],[3,2,0,1])\n",
    "kte_X_20c = np.transpose(datas['kte_X_20c'],[3,2,0,1])\n",
    "# 验证集\n",
    "val_X_4c = np.transpose(datas['val_X_4c'],[3,2,0,1])\n",
    "val_X_6c = np.transpose(datas['val_X_6c'],[3,2,0,1])\n",
    "val_X_8c = np.transpose(datas['val_X_8c'],[3,2,0,1])\n",
    "val_X_10c = np.transpose(datas['val_X_10c'],[3,2,0,1])\n",
    "val_X_12c = np.transpose(datas['val_X_12c'],[3,2,0,1])\n",
    "val_X_16c = np.transpose(datas['val_X_16c'],[3,2,0,1])\n",
    "val_X_20c = np.transpose(datas['val_X_20c'],[3,2,0,1])\n",
    "# 测试集\n",
    "dte_X_4c = np.transpose(datas['dte_X_4c'],[3,2,0,1])\n",
    "dte_X_6c = np.transpose(datas['dte_X_6c'],[3,2,0,1])\n",
    "dte_X_8c = np.transpose(datas['dte_X_8c'],[3,2,0,1])\n",
    "dte_X_10c = np.transpose(datas['dte_X_10c'],[3,2,0,1])\n",
    "dte_X_12c = np.transpose(datas['dte_X_12c'],[3,2,0,1])\n",
    "dte_X_16c = np.transpose(datas['dte_X_16c'],[3,2,0,1])\n",
    "dte_X_20c = np.transpose(datas['dte_X_20c'],[3,2,0,1])\n",
    "# 标签\n",
    "ktr_Y_4c = datas['ktr_Y_4c']\n",
    "ktr_Y_6c = datas['ktr_Y_6c']\n",
    "ktr_Y_8c = datas['ktr_Y_8c']\n",
    "ktr_Y_10c = datas['ktr_Y_10c']\n",
    "ktr_Y_12c = datas['ktr_Y_12c']\n",
    "ktr_Y_16c = datas['ktr_Y_16c']\n",
    "ktr_Y_20c = datas['ktr_Y_20c']\n",
    "\n",
    "kte_Y_4c = datas['kte_Y_4c']\n",
    "kte_Y_6c = datas['kte_Y_6c']\n",
    "kte_Y_8c = datas['kte_Y_8c']\n",
    "kte_Y_10c = datas['kte_Y_10c']\n",
    "kte_Y_12c = datas['kte_Y_12c']\n",
    "kte_Y_16c = datas['kte_Y_16c']\n",
    "kte_Y_20c = datas['kte_Y_20c']\n",
    "\n",
    "val_Y_4c = datas['val_Y_4c']\n",
    "val_Y_6c = datas['val_Y_6c']\n",
    "val_Y_8c = datas['val_Y_8c']\n",
    "val_Y_10c = datas['val_Y_10c']\n",
    "val_Y_12c = datas['val_Y_12c']\n",
    "val_Y_16c = datas['val_Y_16c']\n",
    "val_Y_20c = datas['val_Y_20c']\n",
    "\n",
    "dte_Y_4c = datas['dte_Y_4c']\n",
    "dte_Y_6c = datas['dte_Y_6c']\n",
    "dte_Y_8c = datas['dte_Y_8c']\n",
    "dte_Y_10c = datas['dte_Y_10c']\n",
    "dte_Y_12c = datas['dte_Y_12c']\n",
    "dte_Y_16c = datas['dte_Y_16c']\n",
    "dte_Y_20c = datas['dte_Y_20c']\n",
    "\n",
    "# 整合到一个列表\n",
    "dataset = {}\n",
    "dataset['ktr_X_4c'] = ktr_X_4c\n",
    "dataset['ktr_X_6c'] = ktr_X_6c\n",
    "dataset['ktr_X_8c'] = ktr_X_8c\n",
    "dataset['ktr_X_10c'] = ktr_X_10c\n",
    "dataset['ktr_X_12c'] = ktr_X_12c\n",
    "dataset['ktr_X_16c'] = ktr_X_16c\n",
    "dataset['ktr_X_20c'] = ktr_X_20c\n",
    "\n",
    "dataset['ktr_Y_4c'] = ktr_Y_4c\n",
    "dataset['ktr_Y_6c'] = ktr_Y_6c\n",
    "dataset['ktr_Y_8c'] = ktr_Y_8c\n",
    "dataset['ktr_Y_10c'] = ktr_Y_10c\n",
    "dataset['ktr_Y_12c'] = ktr_Y_12c\n",
    "dataset['ktr_Y_16c'] = ktr_Y_16c\n",
    "dataset['ktr_Y_20c'] = ktr_Y_20c\n",
    "\n",
    "dataset['kte_X_4c'] = kte_X_4c\n",
    "dataset['kte_X_6c'] = kte_X_6c\n",
    "dataset['kte_X_8c'] = kte_X_8c\n",
    "dataset['kte_X_10c'] = kte_X_10c\n",
    "dataset['kte_X_12c'] = kte_X_12c\n",
    "dataset['kte_X_16c'] = kte_X_16c\n",
    "dataset['kte_X_20c'] = kte_X_20c\n",
    "\n",
    "dataset['kte_Y_4c'] = kte_Y_4c\n",
    "dataset['kte_Y_6c'] = kte_Y_6c\n",
    "dataset['kte_Y_8c'] = kte_Y_8c\n",
    "dataset['kte_Y_10c'] = kte_Y_10c\n",
    "dataset['kte_Y_12c'] = kte_Y_12c\n",
    "dataset['kte_Y_16c'] = kte_Y_16c\n",
    "dataset['kte_Y_20c'] = kte_Y_20c\n",
    "\n",
    "dataset['val_X_4c'] = val_X_4c\n",
    "dataset['val_X_6c'] = val_X_6c\n",
    "dataset['val_X_8c'] = val_X_8c\n",
    "dataset['val_X_10c'] = val_X_10c\n",
    "dataset['val_X_12c'] = val_X_12c\n",
    "dataset['val_X_16c'] = val_X_16c\n",
    "dataset['val_X_20c'] = val_X_20c\n",
    "\n",
    "dataset['val_Y_4c'] = val_Y_4c\n",
    "dataset['val_Y_6c'] = val_Y_6c\n",
    "dataset['val_Y_8c'] = val_Y_8c\n",
    "dataset['val_Y_10c'] = val_Y_10c\n",
    "dataset['val_Y_12c'] = val_Y_12c\n",
    "dataset['val_Y_16c'] = val_Y_16c\n",
    "dataset['val_Y_20c'] = val_Y_20c\n",
    "\n",
    "dataset['dte_X_4c'] = dte_X_4c\n",
    "dataset['dte_X_6c'] = dte_X_6c\n",
    "dataset['dte_X_8c'] = dte_X_8c\n",
    "dataset['dte_X_10c'] = dte_X_10c\n",
    "dataset['dte_X_12c'] = dte_X_12c\n",
    "dataset['dte_X_16c'] = dte_X_16c\n",
    "dataset['dte_X_20c'] = dte_X_20c\n",
    "\n",
    "dataset['dte_Y_4c'] = dte_Y_4c\n",
    "dataset['dte_Y_6c'] = dte_Y_6c\n",
    "dataset['dte_Y_8c'] = dte_Y_8c\n",
    "dataset['dte_Y_10c'] = dte_Y_10c\n",
    "dataset['dte_Y_12c'] = dte_Y_12c\n",
    "dataset['dte_Y_16c'] = dte_Y_16c\n",
    "dataset['dte_Y_20c'] = dte_Y_20c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('../../data/nina_db1/t03.2/s4/Fopgs4_diffratio_07_11_22.npy',dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过CNN后输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "# import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import scipy.io as scio\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "import datetime\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from utils.networks import *\n",
    "from utils.reuse import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 自定义数据集类\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "])\n",
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "num_kn = 20\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self,num_kn = num_kn):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=0\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=32 * 10 * 20, out_features=128)\n",
    "        self.out = nn.Linear(in_features=128, out_features=num_kn)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 32 * 10 * 20)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dr1(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "class EMGDataset(Dataset):\n",
    " \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transforms = transforms.ToTensor()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        emgData = self.data[index,:,:,:]\n",
    "        emgData = np.squeeze(emgData)#似乎不应该压缩了\n",
    "        emglabel = self.label[index]\n",
    "        emglabel = emglabel.astype(np.int16)\n",
    "        emgData = self.transforms(emgData)      \n",
    "        \n",
    "        return emgData,emglabel\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "net = Network(num_kn=num_kn)\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "summary(net, (1, 20, 10), batch_size=1, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集制作\n",
    "# 这里直接用了前面的mat引出的变量，所以没有重新加载数据，直接把前面的代码运行一下就行了\n",
    "# known class for CNN and GAN \n",
    "ktr_Y_4c = ktr_Y_4c[:,0]\n",
    "ktr_Y_6c = ktr_Y_6c[:,0]\n",
    "ktr_Y_8c = ktr_Y_8c[:,0]\n",
    "ktr_Y_10c = ktr_Y_10c[:,0]\n",
    "ktr_Y_12c = ktr_Y_12c[:,0]\n",
    "ktr_Y_16c = ktr_Y_16c[:,0]\n",
    "ktr_Y_20c = ktr_Y_20c[:,0]\n",
    "\n",
    "kte_Y_4c = kte_Y_4c[:,0]\n",
    "kte_Y_6c = kte_Y_6c[:,0]\n",
    "kte_Y_8c = kte_Y_8c[:,0]\n",
    "kte_Y_10c = kte_Y_10c[:,0]\n",
    "kte_Y_12c = kte_Y_12c[:,0]\n",
    "kte_Y_16c = kte_Y_16c[:,0]\n",
    "kte_Y_20c = kte_Y_20c[:,0]\n",
    "\n",
    "ktr_set_4c = EMGDataset(ktr_X_4c,ktr_Y_4c)\n",
    "ktr_set_6c = EMGDataset(ktr_X_6c,ktr_Y_6c)\n",
    "ktr_set_8c = EMGDataset(ktr_X_8c,ktr_Y_8c)\n",
    "ktr_set_10c = EMGDataset(ktr_X_10c,ktr_Y_10c)\n",
    "ktr_set_12c = EMGDataset(ktr_X_12c,ktr_Y_12c)\n",
    "ktr_set_16c = EMGDataset(ktr_X_16c,ktr_Y_16c)\n",
    "ktr_set_20c = EMGDataset(ktr_X_20c,ktr_Y_20c)\n",
    "\n",
    "kte_set_4c = EMGDataset(kte_X_4c,kte_Y_4c)\n",
    "kte_set_6c = EMGDataset(kte_X_6c,kte_Y_6c)\n",
    "kte_set_8c = EMGDataset(kte_X_8c,kte_Y_8c)\n",
    "kte_set_10c = EMGDataset(kte_X_10c,kte_Y_10c)\n",
    "kte_set_12c = EMGDataset(kte_X_12c,kte_Y_12c)\n",
    "kte_set_16c = EMGDataset(kte_X_16c,kte_Y_16c)\n",
    "kte_set_20c = EMGDataset(kte_X_20c,kte_Y_20c)\n",
    "# valiate class as openset for GAN Discriminator,\n",
    "# last number means the count of class\n",
    "val_Y_4c = val_Y_4c[:,0]\n",
    "val_Y_6c = val_Y_6c[:,0]\n",
    "val_Y_8c = val_Y_8c[:,0]\n",
    "val_Y_10c = val_Y_10c[:,0]\n",
    "val_Y_12c = val_Y_12c[:,0]\n",
    "val_Y_16c = val_Y_16c[:,0]\n",
    "val_Y_20c = val_Y_20c[:,0]\n",
    "\n",
    "dte_Y_4c = dte_Y_4c[:,0]\n",
    "dte_Y_6c = dte_Y_6c[:,0]\n",
    "dte_Y_8c = dte_Y_8c[:,0]\n",
    "dte_Y_10c = dte_Y_10c[:,0]\n",
    "dte_Y_12c = dte_Y_12c[:,0]\n",
    "dte_Y_16c = dte_Y_16c[:,0]\n",
    "dte_Y_20c = dte_Y_20c[:,0]\n",
    "\n",
    "val_set_4c = EMGDataset(val_X_4c,val_Y_4c)\n",
    "val_set_6c = EMGDataset(val_X_6c,val_Y_6c)\n",
    "val_set_8c = EMGDataset(val_X_8c,val_Y_8c)\n",
    "val_set_10c = EMGDataset(val_X_10c,val_Y_10c)\n",
    "val_set_12c = EMGDataset(val_X_12c,val_Y_12c)\n",
    "val_set_16c = EMGDataset(val_X_16c,val_Y_16c)\n",
    "val_set_20c = EMGDataset(val_X_20c,val_Y_20c)\n",
    "# dtest,a larger val set, AKA openset\n",
    "dte_set_4c = EMGDataset(dte_X_4c,dte_Y_4c)\n",
    "dte_set_6c = EMGDataset(dte_X_6c,dte_Y_6c)\n",
    "dte_set_8c = EMGDataset(dte_X_8c,dte_Y_8c)\n",
    "dte_set_10c = EMGDataset(dte_X_10c,dte_Y_10c)\n",
    "dte_set_12c = EMGDataset(dte_X_12c,dte_Y_12c)\n",
    "dte_set_16c = EMGDataset(dte_X_16c,dte_Y_16c)\n",
    "dte_set_20c = EMGDataset(dte_X_20c,dte_Y_20c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=20, bias=True)\n",
       "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算数据集的网络预测输出并构建新的特征向量四维 array\n",
    "# 注意迭代器只能建立一次，然后以此前进，所以这里单列一行，避免重复建设\n",
    "# 达成类似目标的做法有很多种，例如 append() 等，这里先完成功能，优化待后来同学了\n",
    "\n",
    "def emgdata_to_net_preds(data_set,net_vector):\n",
    "    batchl = iter(data_set)\n",
    "    emg_vec = [torch.tensor([],requires_grad=False) for i in range(len(data_set.label))]\n",
    "    for idx, _ in enumerate(emg_vec):\n",
    "        sample_data,sample_label = next(batchl)\n",
    "        sample_data = sample_data.to(torch.float32).unsqueeze(0)\n",
    "        sample_label = torch.as_tensor(sample_label).long()\n",
    "        emg_vec[idx] = net_vector(sample_data).detach().numpy()\n",
    "    emg_vec_np = np.array(emg_vec)\n",
    "    emg_vec_np = emg_vec_np[:,np.newaxis,:,:]\n",
    "    return emg_vec_np\n",
    "# 使用训练好的模型，用其输出构建新数据集\n",
    "# 这段感觉应该放在数据处理的，但好像不是那么好切割开，就先这样吧\n",
    "path_4c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc4.pth')\n",
    "path_6c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc6.pth')\n",
    "path_8c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc8.pth')\n",
    "path_10c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc10.pth')\n",
    "path_12c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc12.pth')\n",
    "path_16c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc16.pth')\n",
    "path_20c = torch.load('..\\model\\opg_testops_220628a\\s4\\c_kc20.pth')\n",
    "\n",
    "net_4c = Network(num_kn=4)\n",
    "net_4c.load_state_dict(path_4c)\n",
    "net_4c.eval()\n",
    "net_6c = Network(num_kn=6)\n",
    "net_6c.load_state_dict(path_6c)\n",
    "net_6c.eval()\n",
    "net_8c = Network(num_kn=8)\n",
    "net_8c.load_state_dict(path_8c)\n",
    "net_8c.eval()\n",
    "net_10c = Network(num_kn=10)\n",
    "net_10c.load_state_dict(path_10c)\n",
    "net_10c.eval()\n",
    "net_12c = Network(num_kn=12)\n",
    "net_12c.load_state_dict(path_12c)\n",
    "net_12c.eval()\n",
    "net_16c = Network(num_kn=16)\n",
    "net_16c.load_state_dict(path_16c)\n",
    "net_16c.eval()\n",
    "net_20c = Network(num_kn=20)\n",
    "net_20c.load_state_dict(path_20c)\n",
    "net_20c.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec_ktr_X_4c = emgdata_to_net_preds(data_set=ktr_set_4c, net_vector = net_4c)\n",
    "vec_ktr_X_6c = emgdata_to_net_preds(data_set=ktr_set_6c, net_vector = net_6c)\n",
    "vec_ktr_X_8c = emgdata_to_net_preds(data_set=ktr_set_8c, net_vector = net_8c)\n",
    "vec_ktr_X_10c = emgdata_to_net_preds(data_set=ktr_set_10c, net_vector = net_10c)\n",
    "vec_ktr_X_12c = emgdata_to_net_preds(data_set=ktr_set_12c, net_vector = net_12c)\n",
    "vec_ktr_X_16c = emgdata_to_net_preds(data_set=ktr_set_16c, net_vector = net_16c)\n",
    "vec_ktr_X_20c = emgdata_to_net_preds(data_set=ktr_set_20c, net_vector = net_20c)\n",
    "\n",
    "vec_val_X_4c = emgdata_to_net_preds(data_set=val_set_4c, net_vector = net_4c)\n",
    "vec_val_X_6c = emgdata_to_net_preds(data_set=val_set_6c, net_vector = net_6c)\n",
    "vec_val_X_8c = emgdata_to_net_preds(data_set=val_set_8c, net_vector = net_8c)\n",
    "vec_val_X_10c = emgdata_to_net_preds(data_set=val_set_10c, net_vector = net_10c)\n",
    "vec_val_X_12c = emgdata_to_net_preds(data_set=val_set_12c, net_vector = net_12c)\n",
    "vec_val_X_16c = emgdata_to_net_preds(data_set=val_set_16c, net_vector = net_16c)\n",
    "vec_val_X_20c = emgdata_to_net_preds(data_set=val_set_20c, net_vector = net_20c)\n",
    "\n",
    "vec_dte_X_4c = emgdata_to_net_preds(data_set=dte_set_4c, net_vector = net_4c)\n",
    "vec_dte_X_6c = emgdata_to_net_preds(data_set=dte_set_6c, net_vector = net_6c)\n",
    "vec_dte_X_8c = emgdata_to_net_preds(data_set=dte_set_8c, net_vector = net_8c)\n",
    "vec_dte_X_10c = emgdata_to_net_preds(data_set=dte_set_10c, net_vector = net_10c)\n",
    "vec_dte_X_12c = emgdata_to_net_preds(data_set=dte_set_12c, net_vector = net_12c)\n",
    "vec_dte_X_16c = emgdata_to_net_preds(data_set=dte_set_16c, net_vector = net_16c)\n",
    "vec_dte_X_20c = emgdata_to_net_preds(data_set=dte_set_20c, net_vector = net_20c)\n",
    "\n",
    "vec_kte_X_4c = emgdata_to_net_preds(data_set=kte_set_4c, net_vector = net_4c)\n",
    "vec_kte_X_6c = emgdata_to_net_preds(data_set=kte_set_6c, net_vector = net_6c)\n",
    "vec_kte_X_8c = emgdata_to_net_preds(data_set=kte_set_8c, net_vector = net_8c)\n",
    "vec_kte_X_10c = emgdata_to_net_preds(data_set=kte_set_10c, net_vector = net_10c)\n",
    "vec_kte_X_12c = emgdata_to_net_preds(data_set=kte_set_12c, net_vector = net_12c)\n",
    "vec_kte_X_16c = emgdata_to_net_preds(data_set=kte_set_16c, net_vector = net_16c)\n",
    "vec_kte_X_20c = emgdata_to_net_preds(data_set=kte_set_20c, net_vector = net_20c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 详细说明见 utils/dataprocess.py\n",
    "# 为什么这个函数会把原始的dataset_Y值也改变了？涉及可变对象要深拷贝\n",
    "import copy\n",
    "def emgdata_label_tsp_01_v2(dataset_Y,num_knclass):\n",
    "    emg_label = copy.deepcopy(dataset_Y[:])\n",
    "    kn_idx = (emg_label < num_knclass)\n",
    "    kn_idx = kn_idx.squeeze()\n",
    "    un_idx = (emg_label >= num_knclass)\n",
    "    un_idx = un_idx.squeeze()\n",
    "    emg_label[kn_idx] = 1\n",
    "    emg_label[un_idx] = 0\n",
    "    return emg_label\n",
    "# 为什么只是让标签变成01，名字中也带 vec 呢（vec是指网络输出后的向量），\n",
    "# 我只是想让他们处于一个批次，这样一加载 vec x（显然只有训练GAN 才用得上），\n",
    "# 就想起来得加载 vec_y\n",
    "vec_val_Y_4c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_4c, num_knclass=21)\n",
    "vec_val_Y_6c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_6c, num_knclass=21)\n",
    "vec_val_Y_8c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_8c, num_knclass=21)\n",
    "vec_val_Y_10c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_10c, num_knclass=21)\n",
    "vec_val_Y_12c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_12c, num_knclass=21)\n",
    "vec_val_Y_16c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_16c, num_knclass=21)\n",
    "vec_val_Y_20c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_20c, num_knclass=21)\n",
    "\n",
    "vec_dte_Y_4c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_4c, num_knclass=21)\n",
    "vec_dte_Y_6c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_6c, num_knclass=21)\n",
    "vec_dte_Y_8c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_8c, num_knclass=21)\n",
    "vec_dte_Y_10c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_10c, num_knclass=21)\n",
    "vec_dte_Y_12c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_12c, num_knclass=21)\n",
    "vec_dte_Y_16c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_16c, num_knclass=21)\n",
    "vec_dte_Y_20c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_20c, num_knclass=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 现在组合数据集，合到dataset这个dict 就够了，没必要新建变量\n",
    "dataset['vec_ktr_X_4c'] = vec_ktr_X_4c\n",
    "dataset['vec_ktr_X_6c'] = vec_ktr_X_6c\n",
    "dataset['vec_ktr_X_8c'] = vec_ktr_X_8c\n",
    "dataset['vec_ktr_X_10c'] = vec_ktr_X_10c\n",
    "dataset['vec_ktr_X_12c'] = vec_ktr_X_12c\n",
    "dataset['vec_ktr_X_16c'] = vec_ktr_X_16c\n",
    "dataset['vec_ktr_X_20c'] = vec_ktr_X_20c\n",
    "\n",
    "dataset['vec_kte_X_4c'] = vec_kte_X_4c\n",
    "dataset['vec_kte_X_6c'] = vec_kte_X_6c\n",
    "dataset['vec_kte_X_8c'] = vec_kte_X_8c\n",
    "dataset['vec_kte_X_10c'] = vec_kte_X_10c\n",
    "dataset['vec_kte_X_12c'] = vec_kte_X_12c\n",
    "dataset['vec_kte_X_16c'] = vec_kte_X_16c\n",
    "dataset['vec_kte_X_20c'] = vec_kte_X_20c\n",
    "\n",
    "dataset['vec_val_X_4c'] = vec_val_X_4c\n",
    "dataset['vec_val_X_6c'] = vec_val_X_6c\n",
    "dataset['vec_val_X_8c'] = vec_val_X_8c\n",
    "dataset['vec_val_X_10c'] = vec_val_X_10c\n",
    "dataset['vec_val_X_12c'] = vec_val_X_12c\n",
    "dataset['vec_val_X_16c'] = vec_val_X_16c\n",
    "dataset['vec_val_X_20c'] = vec_val_X_20c\n",
    "\n",
    "dataset['vec_dte_X_4c'] = vec_dte_X_4c\n",
    "dataset['vec_dte_X_6c'] = vec_dte_X_6c\n",
    "dataset['vec_dte_X_8c'] = vec_dte_X_8c\n",
    "dataset['vec_dte_X_10c'] = vec_dte_X_10c\n",
    "dataset['vec_dte_X_12c'] = vec_dte_X_12c\n",
    "dataset['vec_dte_X_16c'] = vec_dte_X_16c\n",
    "dataset['vec_dte_X_20c'] = vec_dte_X_20c\n",
    "\n",
    "dataset['vec_val_Y_4c'] = vec_val_Y_4c\n",
    "dataset['vec_val_Y_6c'] = vec_val_Y_6c\n",
    "dataset['vec_val_Y_8c'] = vec_val_Y_8c\n",
    "dataset['vec_val_Y_10c'] = vec_val_Y_10c\n",
    "dataset['vec_val_Y_12c'] = vec_val_Y_12c\n",
    "dataset['vec_val_Y_16c'] = vec_val_Y_16c\n",
    "dataset['vec_val_Y_20c'] = vec_val_Y_20c\n",
    "\n",
    "dataset['vec_dte_Y_4c'] = vec_dte_Y_4c\n",
    "dataset['vec_dte_Y_6c'] = vec_dte_Y_6c\n",
    "dataset['vec_dte_Y_8c'] = vec_dte_Y_8c\n",
    "dataset['vec_dte_Y_10c'] = vec_dte_Y_10c\n",
    "dataset['vec_dte_Y_12c'] = vec_dte_Y_12c\n",
    "dataset['vec_dte_Y_16c'] = vec_dte_Y_16c\n",
    "dataset['vec_dte_Y_20c'] = vec_dte_Y_20c\n",
    "\n",
    "np.save(\"../../data/nina_db1/t03.2/s4/Fopg_s4_diff_ratio_vec_20220712.npy\", dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b50118325a7626417fe50d71eb3710ab5f255b49a222255d7cbf2e46b54f8133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
