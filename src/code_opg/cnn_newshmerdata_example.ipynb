{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN on EMG\n",
    "修订日期：22.5.18\n",
    "本代码展示CNN在EMG上训练和测试的示例。所有代码与OPG_EMG 的前半部分相似，即截取了GAN训练前的部分。\n",
    "\n",
    "本示例展示了从含有六类肌电信号的数据集中训练出六分类的 CNN，数据集来自自采数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import tree \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as scio\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.reuse import *\n",
    "from utils.networks import *\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备操作\n",
    "设置检查点、visdom 日志文件存储等日志性文件存储位置；\n",
    "初始化 visdom,记得先在命令行输入 visdom 运行（python环境下）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_05_18_15_17_59\n"
     ]
    }
   ],
   "source": [
    "# 以下是检查点路径\n",
    "# 请在当前环境下 CMD 输入python -m visdom.server 或 visdom 启动监视器\n",
    "# 数据处理现在已移至 emgDataprocess.ipynb\n",
    "# 现在model_Dir 作为所有文件的父目录，不再分设开导致文件难寻\n",
    "model_Dir = \".//model//opg_0217a//\"\n",
    "if not os.path.exists(model_Dir):\n",
    "    os.makedirs(model_Dir)\n",
    "# 这是正常定期检查点存储位置\n",
    "ckpDir = model_Dir + \"ckp//\"\n",
    "if not os.path.exists(ckpDir):\n",
    "    os.makedirs(ckpDir)\n",
    "# 这里是特挑最佳AUC的位置\n",
    "ckpDir_auc = ckpDir + \"auc//\"\n",
    "if not os.path.exists(ckpDir_auc):\n",
    "    os.makedirs(ckpDir_auc)\n",
    "# 这是 visdom 日志文件存储位置，留待备用\n",
    "vislogDir = model_Dir + \"vislog//\"\n",
    "if not os.path.exists(vislogDir):\n",
    "    os.makedirs(vislogDir)\n",
    "\n",
    "def get_current_time():\n",
    "    return datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "print(get_current_time())\n",
    "\n",
    "timeForSave = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是 visdom 监视窗口初始化，实现每次启用时重新加载，这里只写了 NameError 以防其他错误不能被发现\n",
    "# 如果没有下载 visdom 需要提前下载并配置好，或者自行注释掉相关部分以避免启用\n",
    "class visdom_account:\n",
    "    def __init__(self):\n",
    "        self.port = 8097\n",
    "        self.server = \"http://localhost\"\n",
    "        self.base_url = \"/\"\n",
    "        self.username = \"admin\"\n",
    "        self.passward = \"1234\"\n",
    "        self.evns = \"train\"\n",
    "\n",
    "\n",
    "viz_acnt = visdom_account()\n",
    "\n",
    "\n",
    "def viz_init():\n",
    "    try:\n",
    "        viz\n",
    "    except NameError:\n",
    "        viz = Visdom(\n",
    "            env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + timeForSave\n",
    "        )\n",
    "        print(\"visdom has started\")\n",
    "    else:\n",
    "        viz.close()\n",
    "        del viz\n",
    "        print(\"last visdom session closed\")\n",
    "        viz = Visdom(\n",
    "            env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + timeForSave\n",
    "        )\n",
    "        print(\"visdom has restarted\")\n",
    "    return viz\n",
    "\n",
    "\n",
    "viz = viz_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络结构\n",
    "CNN 训练部分，为了获得一个已知类分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=25344, out_features=128, bias=True)\n",
      "  (out): Linear(in_features=128, out_features=6, bias=True)\n",
      "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 32, 200, 6]             320\n",
      "            Conv2d-2            [1, 32, 199, 5]           9,248\n",
      "            Linear-3                   [1, 128]       3,244,160\n",
      "         Dropout2d-4                   [1, 128]               0\n",
      "            Linear-5                     [1, 6]             774\n",
      "================================================================\n",
      "Total params: 3,254,502\n",
      "Trainable params: 3,254,502\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.54\n",
      "Params size (MB): 12.41\n",
      "Estimated Total Size (MB): 12.96\n",
      "----------------------------------------------------------------\n",
      "Outputshape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=0\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=32 * 4 * 198, out_features=128)\n",
    "        self.out = nn.Linear(in_features=128, out_features=6)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 32 * 4 * 198)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dr1(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "net = Network()\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "print(net)\n",
    "summary(net, (1, 200, 6), batch_size=1, device=\"cpu\")\n",
    "# 可视化结构，torchviz\n",
    "sampleInput = torch.randn(1, 1, 200, 6).requires_grad_(True)\n",
    "sampleOutput = net(sampleInput)\n",
    "print(\"Outputshape:\", sampleOutput.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载、构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<iterator object at 0x000001E42543F2B0>\n"
     ]
    }
   ],
   "source": [
    "# CNN训练数据加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "])\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    " \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transforms = transform\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        emgData = self.data[index,:,:,:]\n",
    "        emgData = np.squeeze(emgData)\n",
    "        emglabel = self.label[index]\n",
    "        emglabel = emglabel.astype(np.int16)\n",
    "        emgData = self.transforms(emgData)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)     \n",
    "        return emgData,emglabel\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    " \n",
    " \n",
    "# if __name__ == '__main__':\n",
    "dataarray = np.load('../../data/OpenganDataSet_220217a_0226.npy',allow_pickle=True)\n",
    "CNNdataset = dataarray.item()\n",
    "print(type(CNNdataset))\n",
    "traindata = CNNdataset['Xtrain']\n",
    "trainlabel = CNNdataset['Ytrain']\n",
    "testdata = CNNdataset['Xtest']\n",
    "testlabel = CNNdataset['Ytest']\n",
    "valdata = CNNdataset['Xval']\n",
    "vallabel = CNNdataset['Yval']\n",
    "\n",
    "trainlabel = trainlabel[:,0]\n",
    "testlabel = testlabel[:,0]\n",
    "vallabel = vallabel[:,0]\n",
    "# trainunknownc_label = trainunknownc_label[:,0]\n",
    "# print(type(trainlabel))\n",
    "train_set = EMGDataset(traindata, trainlabel)\n",
    "test_set = EMGDataset(testdata, testlabel)\n",
    "val_set = EMGDataset(valdata, vallabel)\n",
    "# train_unknown = EMGDataset(trainunknown_data,trainunknownc_label)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, pin_memory=True,\n",
    "#                                             num_workers=3)\n",
    "\n",
    "# 试运行数据集，构建迭代器\n",
    "sample = iter(test_set)\n",
    "print(sample)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=2, shuffle=False)\n",
    "batch1 = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 1, 200, 6]) tensor([[[[ 0.0560,  0.0085,  0.0103, -0.0063,  0.0692, -0.0128],\n",
      "          [ 0.0630,  0.0048,  0.0117, -0.0094,  0.0801,  0.0112],\n",
      "          [ 0.0523,  0.0097,  0.0128, -0.0087,  0.0571,  0.0216],\n",
      "          ...,\n",
      "          [ 0.0189,  0.0077, -0.0629,  0.1049,  0.1224, -0.0539],\n",
      "          [ 0.0183,  0.0043, -0.0636,  0.0571,  0.1217, -0.0036],\n",
      "          [ 0.0197, -0.0033, -0.0216, -0.0099,  0.0616,  0.0214]]],\n",
      "\n",
      "\n",
      "        [[[-0.0192,  0.0187, -0.0082,  0.0171, -0.1246,  0.0031],\n",
      "          [-0.0205,  0.0269, -0.0022, -0.0093, -0.0880, -0.0135],\n",
      "          [-0.0192,  0.0206,  0.0065, -0.0338, -0.0170,  0.0189],\n",
      "          ...,\n",
      "          [-0.0324, -0.0698,  0.0012,  0.0213, -0.0666,  0.0129],\n",
      "          [-0.0182, -0.0770, -0.0173,  0.0614, -0.0370,  0.0245],\n",
      "          [ 0.0020, -0.0550, -0.0124,  0.0411, -0.0115,  0.0102]]]],\n",
      "       dtype=torch.float64) \n",
      " y: torch.Size([2]) tensor([0, 0], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "batch2 = next(batch1)\n",
    "d_x,d_y = batch2\n",
    "print(\n",
    "    \"x:\",\n",
    "    d_x.shape,\n",
    "    d_x,\n",
    "    \"\\n\",\n",
    "    \"y:\",\n",
    "    d_y.shape,\n",
    "    d_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visdom has started\n",
      "epoch 0 total_train_acc: 0.20222434824204735 loss: 59.06453335285187 test_loss: 1.7725965976715088 test_acc: 0.325619384699156\n",
      "epoch 1 total_train_acc: 0.26201865582396555 loss: 57.75129568576813 test_loss: 1.7197678089141846 test_acc: 0.24802613667301934\n",
      "epoch 2 total_train_acc: 0.35745037072470703 loss: 53.50155305862427 test_loss: 1.524469017982483 test_acc: 0.4353389599782194\n",
      "epoch 3 total_train_acc: 0.41664673523080603 loss: 47.39896774291992 test_loss: 1.2795482873916626 test_acc: 0.5085760958344677\n",
      "epoch 4 total_train_acc: 0.4869648409471418 loss: 42.70749843120575 test_loss: 1.3570644855499268 test_acc: 0.6496052273346039\n",
      "epoch 5 total_train_acc: 0.5520210475962688 loss: 38.62566924095154 test_loss: 1.0890090465545654 test_acc: 0.7032398584263545\n",
      "epoch 6 total_train_acc: 0.6144463047117914 loss: 35.16096884012222 test_loss: 1.2244209051132202 test_acc: 0.7258371903076504\n",
      "epoch 7 total_train_acc: 0.6645539344654389 loss: 31.741951048374176 test_loss: 0.9727004766464233 test_acc: 0.7939014429621563\n",
      "epoch 8 total_train_acc: 0.7126285577613011 loss: 28.646160125732422 test_loss: 0.7982374429702759 test_acc: 0.7982575551320447\n",
      "epoch 9 total_train_acc: 0.747070078928486 loss: 26.193671941757202 test_loss: 0.6961683630943298 test_acc: 0.8295671113531173\n",
      "epoch 10 total_train_acc: 0.7831858407079646 loss: 23.75155282020569 test_loss: 0.728130578994751 test_acc: 0.8224884290770488\n",
      "epoch 11 total_train_acc: 0.8010045443673762 loss: 21.982835590839386 test_loss: 0.7795622944831848 test_acc: 0.8483528450857609\n",
      "epoch 12 total_train_acc: 0.8307821095431714 loss: 20.01050728559494 test_loss: 0.4758749008178711 test_acc: 0.8676830928396406\n",
      "epoch 13 total_train_acc: 0.8451327433628318 loss: 18.35129162669182 test_loss: 0.574787437915802 test_acc: 0.8788456302749795\n",
      "epoch 14 total_train_acc: 0.8555369528820856 loss: 16.76769521832466 test_loss: 0.5460542440414429 test_acc: 0.8853797985298122\n",
      "epoch 15 total_train_acc: 0.8798134417603444 loss: 15.192653387784958 test_loss: 1.0013413429260254 test_acc: 0.8992649060713314\n",
      "epoch 16 total_train_acc: 0.8890217651279598 loss: 13.904567420482635 test_loss: 0.4070852994918823 test_acc: 0.8968145929757692\n",
      "epoch 17 total_train_acc: 0.9080363549390098 loss: 12.390663117170334 test_loss: 0.2694304883480072 test_acc: 0.9229512659950994\n",
      "epoch 18 total_train_acc: 0.9165271466156422 loss: 11.172095209360123 test_loss: 0.2258794903755188 test_acc: 0.9365641165260006\n",
      "epoch 19 total_train_acc: 0.9270509447500598 loss: 10.179161846637726 test_loss: 0.3572072982788086 test_acc: 0.9381976585897087\n",
      "epoch 20 total_train_acc: 0.9307581918201387 loss: 9.497391656041145 test_loss: 0.32947155833244324 test_acc: 0.9112442145385243\n",
      "epoch 21 total_train_acc: 0.9374551542693136 loss: 8.694611936807632 test_loss: 0.401631236076355 test_acc: 0.9409202286958889\n",
      "epoch 22 total_train_acc: 0.9435541736426692 loss: 8.014202997088432 test_loss: 0.18678994476795197 test_acc: 0.9548053362374082\n",
      "epoch 23 total_train_acc: 0.9484573068643866 loss: 7.402175456285477 test_loss: 0.47121375799179077 test_acc: 0.9515382521099919\n",
      "epoch 24 total_train_acc: 0.9513274336283186 loss: 7.021518662571907 test_loss: 0.3324710726737976 test_acc: 0.9564388783011163\n",
      "epoch 25 total_train_acc: 0.9485768954795504 loss: 7.000734761357307 test_loss: 0.1843569427728653 test_acc: 0.9515382521099919\n",
      "epoch 26 total_train_acc: 0.9564697440803636 loss: 6.159651845693588 test_loss: 0.9804941415786743 test_acc: 0.9594337054179145\n",
      "epoch 27 total_train_acc: 0.952523319779957 loss: 6.370191685855389 test_loss: 0.1554340273141861 test_acc: 0.9610672474816226\n",
      "epoch 28 total_train_acc: 0.9594594594594594 loss: 5.631073027849197 test_loss: 0.07749278098344803 test_acc: 0.9629730465559488\n",
      "epoch 29 total_train_acc: 0.9610141114565893 loss: 5.490336798131466 test_loss: 0.20531892776489258 test_acc: 0.9504492240675197\n",
      "epoch 30 total_train_acc: 0.9599378139201148 loss: 5.493444740772247 test_loss: 0.5209409594535828 test_acc: 0.9509937380887558\n",
      "epoch 31 total_train_acc: 0.9636450609901938 loss: 5.106087744235992 test_loss: 0.2489928901195526 test_acc: 0.9605227334603866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2212/472525235.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtrainloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calculate Gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Update Weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrainloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mcurr_total_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_num_correct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mtotal_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurr_total_correct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN 训练\n",
    "# 损失\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# 加载数据，设置优化器\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=True)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0002)\n",
    "lr_schedule = torch.optim.lr_scheduler.StepLR(optimizer, 100, gamma=0.5, last_epoch=-1)\n",
    "# 初始化 visdom\n",
    "viz.close()\n",
    "viz = viz_init()\n",
    "if not os.path.exists(vislogDir):\n",
    "    os.makedirs(vislogDir)\n",
    "viz = Visdom(\n",
    "    env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + get_current_time()\n",
    ")\n",
    "vizx = 0\n",
    "viz.text(\n",
    "    \"MONITOR: Show train process~~\",\n",
    "    win=\"Monitor\",\n",
    "    opts={\n",
    "        \"title\": \"ProcessMonitor\",\n",
    "    },\n",
    ")\n",
    "\n",
    "total_test_acc = 0\n",
    "total_test_correct = 0\n",
    "totaltest = 0\n",
    "# 训练过程\n",
    "epoch_num = 600\n",
    "net.to(device)\n",
    "for epoch in range(epoch_num):\n",
    "    viz.text(\n",
    "        \"ep\" + str(epoch + 1) + \" start\",\n",
    "        win=\"Monitor\",\n",
    "        opts={\n",
    "            \"title\": \"ProcessMonitor\",\n",
    "        },\n",
    "    )\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    curr_total_correct = 0\n",
    "    total_traintnum = 0\n",
    "    for batch in train_loader:\n",
    "        # 载入本批次数据\n",
    "        images, labels = batch\n",
    "        images = images.to(torch.float32)\n",
    "        labels = labels.long()\n",
    "        net.train()\n",
    "        preds = net(images.to(device))\n",
    "        trainloss = F.cross_entropy(preds.to(device), labels.to(device))  # 真实数据的鉴别器损失\n",
    "        optimizer.zero_grad()\n",
    "        trainloss.backward()  # Calculate Gradients\n",
    "        optimizer.step()  # Update Weight\n",
    "        total_loss += trainloss.item()\n",
    "        curr_total_correct = get_num_correct(preds.to(device), labels.to(device))\n",
    "        total_correct += curr_total_correct\n",
    "        total_traintnum += labels.size(0)\n",
    "    total_train_acc = total_correct / total_traintnum\n",
    "    total_correct = 0\n",
    "    # 测试\n",
    "    net.eval()\n",
    "    total_testnum = 0\n",
    "    for testemgdatas, testemglabels in test_loader:  # Get Batch\n",
    "        testemgdatas = testemgdatas.to(torch.float32)\n",
    "        testemglabels = testemglabels.long()\n",
    "        predstest = net(testemgdatas.to(device))\n",
    "        testloss = F.cross_entropy(\n",
    "            predstest.to(device), testemglabels.to(device)\n",
    "        )  # Calculate Loss\n",
    "        curr_test_correct = get_num_correct(\n",
    "            predstest.to(device), testemglabels.to(device)\n",
    "        )\n",
    "        total_testnum += testemglabels.size(0)\n",
    "        total_test_correct += curr_test_correct\n",
    "        # totaltest += testemglabels.size(0)\n",
    "    # total_test_acc = total_test_correct/(trainlabel.size)\n",
    "    total_test_acc = total_test_correct / total_testnum\n",
    "    print(\n",
    "        \"epoch\",\n",
    "        epoch,\n",
    "        \"total_train_acc:\",\n",
    "        total_train_acc,\n",
    "        \"loss:\",\n",
    "        total_loss,\n",
    "        \"test_loss:\",\n",
    "        float(testloss),\n",
    "        \"test_acc:\",\n",
    "        total_test_acc,\n",
    "    )\n",
    "    total_test_correct = 0\n",
    "    # 可视化，每 epoch 更新\n",
    "    viz.line(\n",
    "        [float(trainloss)],\n",
    "        [epoch],\n",
    "        win=\"loss_perEpoch\",\n",
    "        name=\"G_loss\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"loss_perEpoch\", xlabel=\"epoch\", ylabel=\"loss\"),\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(testloss)], [epoch], win=\"loss_perEpoch\", name=\"D_loss\", update=\"append\"\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(total_train_acc)],\n",
    "        [epoch],\n",
    "        win=\"acc_perEpoch\",\n",
    "        name=\"train_acc\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"acc_perEpoch\", xlabel=\"epoch\", ylabel=\"acc\"),\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(total_test_acc)],\n",
    "        [epoch],\n",
    "        win=\"acc_perEpoch\",\n",
    "        name=\"test_acc\",\n",
    "        update=\"append\",\n",
    "    )\n",
    "\n",
    "    viz.line(\n",
    "        [float(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])],\n",
    "        [epoch],\n",
    "        win=\"lr_perEpoch\",\n",
    "        name=\"G_loss\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"lr_perEpoch\", xlabel=\"epoch\", ylabel=\"lr\"),\n",
    "    )\n",
    "    # 更新学习率\n",
    "    lr_schedule.step()\n",
    "    # viz.text('updating weights',win='Monitor',append=True,opts = {'title':'ProcessMonitor',},)\n",
    "    # 定期保存\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        timeForSave = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        checkpointPath = (\n",
    "            ckpDir\n",
    "            + \"c_ep_\"\n",
    "            + str(epoch + 1)\n",
    "            + \"_acc\"\n",
    "            + str(int(total_test_acc * 10000))\n",
    "            + \"_\"\n",
    "            + timeForSave\n",
    "            + \".pth\"\n",
    "        )\n",
    "        c_state = {\n",
    "            \"model\": net.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        torch.save(c_state, checkpointPath)\n",
    "        viz.text(\n",
    "            \"epoch \" + str(epoch + 1) + \" model saved\",\n",
    "            win=\"Monitor\",\n",
    "            append=True,\n",
    "            opts={\n",
    "                \"title\": \"ProcessMonitor\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "checkpointPath_model = (\n",
    "    model_Dir\n",
    "    + \"c_final_\"\n",
    "    + \"acc\"\n",
    "    + str(int(total_test_acc * 10000))\n",
    "    + \"_\"\n",
    "    + timeForSave\n",
    "    + \".pth\"\n",
    ")\n",
    "torch.save(net.state_dict(), checkpointPath_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97f3b3761d073a7e2fe7bca6198a06e63bb287dd409b57ec6cef0ba2122fdc4d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
