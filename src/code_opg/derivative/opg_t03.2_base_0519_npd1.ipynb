{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opg_t03_base_0519_npd1\n",
    "基于 opg_aftertraining0519.ipynb\n",
    "本代码主要完成ninapro db1 同 subject 下，不同的模型已知类数量对结果的影响验证工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torchviz import make_dot\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import tree \n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.networks import *\n",
    "from utils.reuse import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备操作\n",
    "设置检查点、visdom 日志文件存储等日志性文件存储位置；\n",
    "初始化 visdom,记得先在命令行输入 visdom 运行（python环境下）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是检查点路径\n",
    "# 请在当前环境下 CMD 输入python -m visdom.server 或 visdom 启动监视器\n",
    "# 数据处理现在已移至 emgDataprocess.ipynb\n",
    "# 现在model_Dir 作为所有文件的父目录，不再分设开导致文件难寻\n",
    "model_Dir = \"..//model//opg_testops_t03.2_220712a//s1//\"\n",
    "if not os.path.exists(model_Dir):\n",
    "    os.makedirs(model_Dir)\n",
    "# 这是正常定期检查点存储位置\n",
    "ckpDir = model_Dir + \"ckp//\"\n",
    "if not os.path.exists(ckpDir):\n",
    "    os.makedirs(ckpDir)\n",
    "# 这里是特挑最佳AUC的位置\n",
    "ckpDir_auc = ckpDir + \"auc//\"\n",
    "if not os.path.exists(ckpDir_auc):\n",
    "    os.makedirs(ckpDir_auc)\n",
    "# 这是 visdom 日志文件存储位置，留待备用\n",
    "vislogDir = model_Dir + \"vislog//\"\n",
    "if not os.path.exists(vislogDir):\n",
    "    os.makedirs(vislogDir)\n",
    "\n",
    "def get_current_time():\n",
    "    return datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "print(get_current_time())\n",
    "\n",
    "timeForSave = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是 visdom 监视窗口初始化，实现每次启用时重新加载，这里只写了 NameError 以防其他错误不能被发现\n",
    "class visdom_account:\n",
    "    def __init__(self):\n",
    "        self.port = 8097\n",
    "        self.server = \"http://localhost\"\n",
    "        self.base_url = \"/\"\n",
    "        self.username = \"admin\"\n",
    "        self.passward = \"1234\"\n",
    "        self.evns = \"train_opg_t03_s1\"\n",
    "\n",
    "\n",
    "viz_acnt = visdom_account()\n",
    "\n",
    "\n",
    "def viz_init():\n",
    "    try:\n",
    "        viz\n",
    "    except NameError:\n",
    "        viz = Visdom(\n",
    "            env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + timeForSave\n",
    "        )\n",
    "        print(\"visdom has started\")\n",
    "    else:\n",
    "        viz.close()\n",
    "        del viz\n",
    "        print(\"last visdom session closed\")\n",
    "        viz = Visdom(\n",
    "            env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + timeForSave\n",
    "        )\n",
    "        print(\"visdom has restarted\")\n",
    "    return viz\n",
    "\n",
    "\n",
    "viz = viz_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG需要转化成6维特征，用到刚刚训练的模型c_ep_200_acc9763_2022_02_26_23_18_44,\n",
    "# 并重组为新数据集OpenganDatafea_smr_10cl_220227.npy，步骤见 emgDataprocess.ipynb\n",
    "num_kc = 4\n",
    "# opGAN部分开始\n",
    "# GAN 模型搭建\n",
    "# 潜在张量大小,32，4是因为 cnn feature 只有6个，不好比它大\n",
    "latent_size = 4\n",
    "# 输出通道数\n",
    "n_channel = num_kc\n",
    "# 生成网络隐藏层大小\n",
    "n_g_feature = 64\n",
    "\n",
    "gnet = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(latent_size, n_g_feature * 1),  # 用线性变换将输入映射到64维\n",
    "    nn.BatchNorm1d(n_g_feature * 1),\n",
    "    nn.ReLU(True),  # relu激活\n",
    "    nn.Dropout2d(0.2),\n",
    "    nn.Linear(n_g_feature * 1, n_g_feature * 2),  # 线性变换\n",
    "    nn.BatchNorm1d(n_g_feature * 2),\n",
    "    nn.ReLU(True),  # relu激活\n",
    "    nn.Dropout2d(0.2),\n",
    "    nn.Linear(n_g_feature * 2, n_channel),  # 线性变换\n",
    ").to(device)\n",
    "gnet.to(\"cpu\")\n",
    "# print(gnet)\n",
    "summary(gnet, (1, 1, 4), batch_size=1, device=\"cpu\")\n",
    "gnet.to(device)\n",
    "# 鉴别网络隐藏层大小\n",
    "# 32,\n",
    "n_d_feature = 64\n",
    "dnet = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(n_channel, n_d_feature * 2),  # 输入特征数为784，输出为256\n",
    "    nn.BatchNorm1d(n_d_feature * 2),\n",
    "    nn.LeakyReLU(0.2),  # 进行非线性映射\n",
    "    nn.Dropout2d(0.2),\n",
    "    nn.Linear(n_d_feature * 2, n_d_feature),  # 进行一个线性映射\n",
    "    nn.BatchNorm1d(n_d_feature),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Dropout2d(0.2),\n",
    "    nn.Linear(n_d_feature, 1),\n",
    "    # nn.Sigmoid()  # 也是一个激活函数，二分类问题中，\n",
    "    # sigmoid可以班实数映射到【0,1】，作为概率值，\n",
    "    # 多分类用softmax函数\n",
    ").to(device)\n",
    "# print(dnet)\n",
    "dnet.to(\"cpu\")\n",
    "summary(dnet, (1, 1, num_kc), batch_size=1, device=\"cpu\")\n",
    "dnet.to(device)\n",
    "# 初始化权重\n",
    "def weights_init(m):\n",
    "    if type(m) in [nn.ConvTranspose2d, nn.Conv2d]:\n",
    "        init.xavier_normal_(m.weight)\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        init.normal_(m.weight, 1.0, 0.02)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "gnet.apply(weights_init)\n",
    "dnet.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN 数据加载，构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 openGAN 所需数据，这里只有训练、验证两部分，没有测试集，因为本次数据采集划分时只划出两部分，不影响最终结果\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "    ]\n",
    ")\n",
    "GAN_dataarray = np.load(\"../../data/nina_db1/t03.2/s1/Fopg_s1_diff_ratio_vec_20220712.npy\", allow_pickle=True)\n",
    "GANdataset = GAN_dataarray.item()\n",
    "print(type(GANdataset))\n",
    "\n",
    "ktr_str_X = \"vec_ktr_X_\"+str(num_kc)+\"c\"\n",
    "ktr_str_Y = \"ktr_Y_\"+str(num_kc)+\"c\"\n",
    "val_str_X = \"vec_val_X_\"+str(num_kc)+\"c\"\n",
    "val_str_Y = \"vec_val_Y_\"+str(num_kc)+\"c\"\n",
    "dte_str_X = \"vec_dte_X_\"+str(num_kc)+\"c\"\n",
    "dte_str_Y = \"dte_Y_\"+str(num_kc)+\"c\"\n",
    "\n",
    "traindata = GANdataset[ktr_str_X]\n",
    "trainlabel = GANdataset[ktr_str_Y]\n",
    "# 本方法中的 test 实际上是个大号的完整版openset,所以标签是01\n",
    "testdata = GANdataset[dte_str_X]\n",
    "testlabel = GANdataset[dte_str_Y]\n",
    "testlabel_for_auc = GANdataset[dte_str_Y]\n",
    "testlabel_for_auc = testlabel_for_auc.ravel()\n",
    "\n",
    "valdata = GANdataset[val_str_X]\n",
    "vallabel = GANdataset[val_str_Y]\n",
    "vallabel_for_auc = GANdataset[val_str_Y]\n",
    "vallabel_for_auc = vallabel_for_auc.ravel()\n",
    "\n",
    "# 注意这里 ktr，kte 的标签需要降维，其他的在数据制作阶段已经降过了\n",
    "# trainlabel = trainlabel[:, 0]\n",
    "# testlabel = testlabel[:,0]\n",
    "# vallabel = vallabel[:, 0]\n",
    "# trainunknownc_label = trainunknownc_label[:,0]\n",
    "# print(type(trainlabel))\n",
    "train_set = EMGDataset_1D(traindata, trainlabel)\n",
    "test_set = EMGDataset_1D(testdata, testlabel)\n",
    "val_set = EMGDataset_1D(valdata, vallabel)\n",
    "# train_unknown = EMGDataset(trainunknown_data,trainunknownc_label)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, pin_memory=True,\n",
    "#                                             num_workers=3)\n",
    "\n",
    "sample = next(iter(train_set))\n",
    "print(sample)\n",
    "sample = next(iter(test_set))\n",
    "print(sample)\n",
    "sample = next(iter(val_set))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN 训练,120\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128)\n",
    "# 损失\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# criterion = F.cross_entropy()\n",
    "# 优化器\n",
    "goptimizer = torch.optim.Adam(gnet.parameters(), lr=0.0008 * 1.5, betas=(0.5, 0.999))\n",
    "doptimizer = torch.optim.Adam(dnet.parameters(), lr=0.4 * 1, betas=(0.5, 0.999))\n",
    "g_lr_schedule = torch.optim.lr_scheduler.StepLR(\n",
    "    goptimizer, 1000, gamma=0.95, last_epoch=-1\n",
    ")\n",
    "d_lr_schedule = torch.optim.lr_scheduler.StepLR(\n",
    "    doptimizer, 1000, gamma=0.95, last_epoch=-1\n",
    ")\n",
    "# 用于测试的固定噪声,用来查看相同的潜在张量在训练过程中生成图片的变换\n",
    "# batch_size = 512\n",
    "# fixed_noises = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "# 初始化 visdom\n",
    "viz.close()\n",
    "viz = viz_init()\n",
    "viz = Visdom(\n",
    "    env=viz_acnt.evns, log_to_filename=vislogDir + \"vislog_\" + get_current_time()\n",
    ")\n",
    "vizx = 0\n",
    "# viz.text(\n",
    "#     \"MONITOR: Show train process~~\",\n",
    "#     win=\"Monitor\",\n",
    "#     opts={\n",
    "#         \"title\": \"ProcessMonitor\",\n",
    "#     },\n",
    "# )\n",
    "# AUC值\n",
    "auc_current = 0\n",
    "auc_max = 0\n",
    "auc_current_te = 0\n",
    "auc_max_te = 0\n",
    "# 训练过程\n",
    "epoch_num = 2500\n",
    "for epoch in range(epoch_num):\n",
    "    # viz.text(\n",
    "    #     \"ep\" + str(epoch + 1) + \" start\",\n",
    "    #     win=\"Monitor\",\n",
    "    #     opts={\n",
    "    #         \"title\": \"ProcessMonitor\",\n",
    "    #     },\n",
    "    # )\n",
    "    dnet.to(device)\n",
    "    for batch in train_loader:\n",
    "        # 载入本批次数据\n",
    "        # real_images, _ = data\n",
    "        # viz.text('load data',win='Monitor',append=True,opts = {'title':'ProcessMonitor',},)\n",
    "        rimages, rlabels = batch\n",
    "        rimages = rimages.to(device)\n",
    "        rlabels = rlabels.to(device)\n",
    "        rimages = rimages.to(torch.float32)\n",
    "        rlabels = rlabels.long()\n",
    "        batch_size = rimages.size(0)\n",
    "        # batch_size = 1344\n",
    "        # viz.text('training',win='Monitor',append=True,opts = {'title':'ProcessMonitor',},)\n",
    "        # 训练鉴别网络\n",
    "        dnet.train()\n",
    "        gnet.train()\n",
    "        labels = torch.ones(batch_size)  # 真实数据对应标签为1\n",
    "        labels = labels.to(device)\n",
    "        preds = dnet(rimages)  # 对真实数据进行判别\n",
    "        preds = preds.reshape(-1)\n",
    "\n",
    "        dloss_real = criterion(preds, labels)  # 真实数据的鉴别器损失\n",
    "        dmean_real = preds.sigmoid().mean()\n",
    "        # 计算鉴别器将多少比例的真数据判定为真,仅用于输出显示\n",
    "\n",
    "        noises = torch.randn(batch_size, latent_size, 1, 1)  # 潜在噪声\n",
    "        noises = noises.to(device)\n",
    "        fake_images = gnet(noises)  # 生成假数据\n",
    "        labels = torch.zeros(batch_size)  # 假数据对应标签为0\n",
    "        labels = labels.to(device)\n",
    "        fake = fake_images.detach()\n",
    "        # 使得梯度的计算不回溯到生成网络,可用于加快训练速度.删去此步结果不变\n",
    "        preds = dnet(fake)  # 对假数据进行鉴别\n",
    "        preds = preds.view(-1)\n",
    "        dloss_fake = criterion(preds, labels)  # 假数据的鉴别器损失\n",
    "        dmean_fake = preds.sigmoid().mean()\n",
    "        # 计算鉴别器将多少比例的假数据判定为真,仅用于输出显示\n",
    "\n",
    "        dloss = dloss_real + dloss_fake  # 总的鉴别器损失\n",
    "        dnet.zero_grad()\n",
    "        dloss.backward()\n",
    "        doptimizer.step()\n",
    "        # now_dloss += dloss.item()\n",
    "        # 训练生成网络\n",
    "        # viz.text(' Generator training',win='Monitor',append=True,opts = {'title':'ProcessMonitor',},)\n",
    "        labels = torch.ones(batch_size)\n",
    "        labels = labels.to(device)\n",
    "        # 生成网络希望所有生成的数据都被认为是真数据\n",
    "        preds = dnet(fake_images)  # 把假数据通过鉴别网络\n",
    "        preds = preds.view(-1)\n",
    "        gloss = criterion(preds, labels)  # 真数据看到的损失\n",
    "        gmean_fake = preds.sigmoid().mean()\n",
    "        # 计算鉴别器将多少比例的假数据判定为真,仅用于输出显示\n",
    "        gnet.zero_grad()\n",
    "        gloss.backward()\n",
    "        goptimizer.step()\n",
    "\n",
    "        # viz.text('train Generator',win='Monitor',append=True,opts = {'title':'ProcessMonitor',},)\n",
    "        print(\n",
    "            \"[{}/{}]\".format(epoch + 1, epoch_num)\n",
    "            + \"D loss:{:g} G loss:{:g}\".format(dloss, gloss)\n",
    "            + \"真判真:{:g} 假判真:{:g}/{:g}\".format(dmean_real, dmean_fake, gmean_fake)\n",
    "        )\n",
    "\n",
    "    # 可视化，每 epoch 更新\n",
    "    viz.line(\n",
    "        [float(gloss)],\n",
    "        [epoch],\n",
    "        win=\"loss_perEpoch\",\n",
    "        name=\"G_loss\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"loss_perEpoch\", xlabel=\"epoch\", ylabel=\"loss\"),\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(dloss)], [epoch], win=\"loss_perEpoch\", name=\"D_loss\", update=\"append\"\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(goptimizer.state_dict()[\"param_groups\"][0][\"lr\"])],\n",
    "        [epoch],\n",
    "        win=\"lr_perEpoch\",\n",
    "        name=\"G_loss\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"lr_perEpoch\", xlabel=\"epoch\", ylabel=\"lr\"),\n",
    "    )\n",
    "    viz.line(\n",
    "        [float(doptimizer.state_dict()[\"param_groups\"][0][\"lr\"])],\n",
    "        [epoch],\n",
    "        win=\"lr_perEpoch\",\n",
    "        name=\"D_loss\",\n",
    "        update=\"append\",\n",
    "    )\n",
    "    # viz.line(\n",
    "    #     [float(dmean_real)],\n",
    "    #     [epoch],\n",
    "    #     win=\"D real_perEpoch\",\n",
    "    #     update=\"append\",\n",
    "    #     opts=dict(title=\"D real真判真_perEpoch\", xlabel=\"epoch\"),\n",
    "    # )\n",
    "    viz.line(\n",
    "        [float(gmean_fake)],\n",
    "        [epoch],\n",
    "        win=\"D fake_perEpoch\",\n",
    "        update=\"append\",\n",
    "        opts=dict(title=\"D fake假判真_perEpoch\", xlabel=\"epoch\"),\n",
    "    )\n",
    "    # 更新学习率\n",
    "    g_lr_schedule.step()\n",
    "    d_lr_schedule.step()\n",
    "    viz.text(\n",
    "        \"updating weights\",\n",
    "        win=\"Monitor\",\n",
    "        append=True,\n",
    "        opts={\n",
    "            \"title\": \"ProcessMonitor\",\n",
    "        },\n",
    "    )\n",
    "    # 定期保存\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        timeForSave = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        checkpointPath_g = (\n",
    "            ckpDir + \"g_ep_\" + str(epoch + 1) + \"_\" + timeForSave + \".pth\"\n",
    "        )\n",
    "        checkpointPath_d = (\n",
    "            ckpDir + \"d_ep_\" + str(epoch + 1) + \"_\" + timeForSave + \".pth\"\n",
    "        )\n",
    "        d_state = {\n",
    "            \"model\": dnet.state_dict(),\n",
    "            \"optimizer\": doptimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        torch.save(d_state, checkpointPath_d)\n",
    "        g_state = {\n",
    "            \"model\": gnet.state_dict(),\n",
    "            \"optimizer\": goptimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        torch.save(g_state, checkpointPath_g)\n",
    "        viz.text(\n",
    "            \"epoch \" + str(epoch + 1) + \" model saved\",\n",
    "            win=\"Monitor\",\n",
    "            append=True,\n",
    "            opts={\n",
    "                \"title\": \"ProcessMonitor\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "    #     计算验证集上的 AUC 值\n",
    "    viz.text(\n",
    "        \"calculate auc start\",\n",
    "        win=\"Monitor\",\n",
    "        opts={\n",
    "            \"title\": \"ProcessMonitor\",\n",
    "        },\n",
    "    )\n",
    "    dnet.eval()\n",
    "    dnet.to(\"cpu\")\n",
    "    emg_vec = emgdata_to_net_preds_sigmoid(data_set=val_set, net_vector=dnet)\n",
    "    emg_vec = emg_vec.ravel()\n",
    "    auc_current = metrics.roc_auc_score(vallabel_for_auc, emg_vec, average=\"micro\")\n",
    "    # ceshiji\n",
    "    emg_vec_te = emgdata_to_net_preds_sigmoid(data_set=test_set, net_vector=dnet)\n",
    "    emg_vec_te = emg_vec_te.ravel()\n",
    "    auc_current_te = metrics.roc_auc_score(testlabel_for_auc, emg_vec_te, average=\"micro\")\n",
    "\n",
    "    viz.line(\n",
    "        [auc_current],\n",
    "        [epoch],\n",
    "        win=\"AUC\",\n",
    "        update=\"append\",\n",
    "        name=\"valiate\",\n",
    "        opts=dict(title=\"AUC\", xlabel=\"epoch\", ylabel=\"AUC\"),\n",
    "    )\n",
    "        \n",
    "    #     保存策略：整个训练过程中最大的AUC及所有AUC值超过0.8的对应模型，由于最大值源于实时比较，刚开始会有一部分低AUC模型被保存，\n",
    "    #     无需在意，过后删去即可\n",
    "    if auc_current > auc_max:\n",
    "        auc_max = auc_current\n",
    "        viz.text(\n",
    "            \"max auc: \" + str(auc_max) + \", in ep \" + str(epoch + 1),\n",
    "            win=\"message\",\n",
    "            append=False,\n",
    "            opts={\n",
    "                \"title\": \"Max AUC\",\n",
    "            },\n",
    "        )\n",
    "                # ceshiji\n",
    "        emg_vec_te = emgdata_to_net_preds_sigmoid(data_set=test_set, net_vector=dnet)\n",
    "        emg_vec_te = emg_vec_te.ravel()\n",
    "        auc_current_te = metrics.roc_auc_score(testlabel_for_auc, emg_vec_te, average=\"micro\")\n",
    "        auc_max_te = auc_current_te\n",
    "        viz.text(\n",
    "            \"max auc_te: \" + str(auc_max_te) + \", in ep \" + str(epoch + 1),\n",
    "            win=\"message_te\",\n",
    "            append=False,\n",
    "            opts={\n",
    "                \"title\": \"Max AUC_te\",\n",
    "            },\n",
    "        )\n",
    "        max_auc_state = {\n",
    "            \"model\": dnet.state_dict(),\n",
    "            \"optimizer\": doptimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        checkpointPath_auc = (\n",
    "            ckpDir_auc\n",
    "            + \"auc_\"\n",
    "            + str(num_kc) +\"kc\"+\n",
    "            + str(int(auc_max * 1000))\n",
    "            + \"d_ep_\"\n",
    "            + str(epoch + 1)\n",
    "            + \"_\"\n",
    "            + timeForSave\n",
    "            + \".pth\"\n",
    "        )\n",
    "        torch.save(max_auc_state, checkpointPath_auc)\n",
    "        viz.text(\n",
    "            \"max auc: \"\n",
    "            + str(auc_max)\n",
    "            + \", in ep \"\n",
    "            + str(epoch + 1)\n",
    "            + \" saved at \"\n",
    "            + checkpointPath_auc,\n",
    "            win=\"message\",\n",
    "            append=True,\n",
    "            opts={\n",
    "                \"title\": \"Max AUC\",\n",
    "            },\n",
    "        )\n",
    "    elif auc_current >= 0.8:\n",
    "        checkpointPath_auc = (\n",
    "            ckpDir_auc\n",
    "            + \"auc_\"\n",
    "            + str(num_kc) +\"kc\"+\n",
    "            + str(int(auc_max * 1000))\n",
    "            + \"d_ep_\"\n",
    "            + str(epoch + 1)\n",
    "            + \"_\"\n",
    "            + timeForSave\n",
    "            + \".pth\"\n",
    "        )\n",
    "        torch.save(max_auc_state, checkpointPath_auc)\n",
    "        viz.text(\n",
    "            \"auc: \"\n",
    "            + str(auc_current)\n",
    "            + \", in ep \"\n",
    "            + str(epoch + 1)\n",
    "            + \" saved at \"\n",
    "            + checkpointPath_auc,\n",
    "            win=\"AUC_Monitor\",\n",
    "            append=True,\n",
    "            opts={\n",
    "                \"title\": \"Max AUC\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "# 完整训练结束后，模型最终保存；意义不大，但以备不时之需\n",
    "checkpointPath_model = (\n",
    "    model_Dir\n",
    "    + \"g_final_\"\n",
    "    + \"acc\"\n",
    "    + str(int(total_test_acc * 10000))\n",
    "    + \"_\"\n",
    "    + timeForSave\n",
    "    + \".pth\"\n",
    ")\n",
    "torch.save(gnet.state_dict(), checkpointPath_model)\n",
    "checkpointPath_model = (\n",
    "    model_Dir\n",
    "    + \"d_final_\"\n",
    "    + \"acc\"\n",
    "    + str(int(total_test_acc * 10000))\n",
    "    + \"_\"\n",
    "    + timeForSave\n",
    "    + \".pth\"\n",
    ")\n",
    "torch.save(dnet.state_dict(), checkpointPath_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证结果\n",
    "绘制 ROC 曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始手势测试集，经过 CNN 后正确率"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "696bc8a05a1eb808e62d18e9328544428937c8e11a4c703581cc2236b7d3d24e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('torchlearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
