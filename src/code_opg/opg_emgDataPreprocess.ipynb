{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "import scipy.io as scio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是mat转numpy用的\n",
    "# 'ktr_X','ktr_Y','kte_X','kte_Y',...\n",
    "#     'val_X_5c','val_Y_5c','dte_X_5c','dte_Y_5c',...\n",
    "#     'val_X_10c','val_Y_10c','dte_X_10c','dte_Y_10c',...\n",
    "#     'val_X_15c','val_Y_15c','dte_X_15c','dte_Y_15c',...\n",
    "#     'val_X_20c','val_Y_20c','dte_X_20c','dte_Y_20c',...\n",
    "#     'val_X_30c','val_Y_30c','dte_X_30c','dte_Y_30c',...\n",
    "#     'val_X_42c','val_Y_42c','dte_X_42c','dte_Y_42c');\n",
    "datas = scio.loadmat('../../data/nina_db1/s5/Fopgs5_multiset_20220619T000442.mat')\n",
    "\n",
    "# 样本\n",
    "ktr_X = np.transpose(datas['ktr_X'],[3,2,0,1])\n",
    "kte_X = np.transpose(datas['kte_X'],[3,2,0,1])\n",
    "val_X_5c = np.transpose(datas['val_X_5c'],[3,2,0,1])\n",
    "val_X_10c = np.transpose(datas['val_X_10c'],[3,2,0,1])\n",
    "val_X_15c = np.transpose(datas['val_X_15c'],[3,2,0,1])\n",
    "val_X_20c = np.transpose(datas['val_X_20c'],[3,2,0,1])\n",
    "val_X_30c = np.transpose(datas['val_X_30c'],[3,2,0,1])\n",
    "val_X_42c = np.transpose(datas['val_X_42c'],[3,2,0,1])\n",
    "\n",
    "dte_X_5c = np.transpose(datas['dte_X_5c'],[3,2,0,1])\n",
    "dte_X_10c = np.transpose(datas['dte_X_10c'],[3,2,0,1])\n",
    "dte_X_15c = np.transpose(datas['dte_X_15c'],[3,2,0,1])\n",
    "dte_X_20c = np.transpose(datas['dte_X_20c'],[3,2,0,1])\n",
    "dte_X_30c = np.transpose(datas['dte_X_30c'],[3,2,0,1])\n",
    "dte_X_42c = np.transpose(datas['dte_X_42c'],[3,2,0,1])\n",
    "# 标签\n",
    "ktr_Y = datas['ktr_Y']\n",
    "kte_Y = datas['kte_Y']\n",
    "val_Y_5c = datas['val_Y_5c']\n",
    "val_Y_10c = datas['val_Y_10c']\n",
    "val_Y_15c = datas['val_Y_15c']\n",
    "val_Y_20c = datas['val_Y_20c']\n",
    "val_Y_30c = datas['val_Y_30c']\n",
    "val_Y_42c = datas['val_Y_42c']\n",
    "\n",
    "dte_Y_5c = datas['dte_Y_5c']\n",
    "dte_Y_10c = datas['dte_Y_10c']\n",
    "dte_Y_15c = datas['dte_Y_15c']\n",
    "dte_Y_20c = datas['dte_Y_20c']\n",
    "dte_Y_30c = datas['dte_Y_30c']\n",
    "dte_Y_42c = datas['dte_Y_42c']\n",
    "\n",
    "# 整合到一个列表\n",
    "dataset = {}\n",
    "dataset['ktr_X'] = ktr_X\n",
    "dataset['ktr_Y'] = ktr_Y\n",
    "dataset['kte_X'] = kte_X\n",
    "dataset['kte_Y'] = kte_Y\n",
    "dataset['val_X_5c'] = val_X_5c\n",
    "dataset['val_Y_5c'] = val_Y_5c\n",
    "dataset['dte_X_5c'] = dte_X_5c\n",
    "dataset['dte_Y_5c'] = dte_Y_5c\n",
    "dataset['val_X_10c'] = val_X_10c\n",
    "dataset['val_Y_10c'] = val_Y_10c\n",
    "dataset['dte_X_10c'] = dte_X_10c\n",
    "dataset['dte_Y_10c'] = dte_Y_10c\n",
    "dataset['val_X_15c'] = val_X_15c\n",
    "dataset['val_Y_15c'] = val_Y_15c\n",
    "dataset['dte_X_15c'] = dte_X_15c\n",
    "dataset['dte_Y_15c'] = dte_Y_15c\n",
    "dataset['val_X_20c'] = val_X_20c\n",
    "dataset['val_Y_20c'] = val_Y_20c\n",
    "dataset['dte_X_20c'] = dte_X_20c\n",
    "dataset['dte_Y_20c'] = dte_Y_20c\n",
    "dataset['val_X_30c'] = val_X_30c\n",
    "dataset['val_Y_30c'] = val_Y_30c\n",
    "dataset['dte_X_30c'] = dte_X_30c\n",
    "dataset['dte_Y_30c'] = dte_Y_30c\n",
    "dataset['val_X_42c'] = val_X_42c\n",
    "dataset['val_Y_42c'] = val_Y_42c\n",
    "dataset['dte_X_42c'] = dte_X_42c\n",
    "dataset['dte_Y_42c'] = dte_Y_42c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save('../../data/nina_db1/s5/Fopgs5_multiset_20220619T000442.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6, 1, 8362)\n",
      "(8362, 1, 200, 6) \n",
      " (3673, 1, 200, 6) \n",
      " (6220, 1, 200, 6) \n",
      "\n",
      "(8362, 1) \n",
      " (3673, 1) \n",
      " (6220, 1) \n",
      "\n",
      "(8362, 1) \n",
      " 8362 0\n"
     ]
    }
   ],
   "source": [
    "# 把用于挑选 GAN 的验证集标签重标注，重新标注应该包括所有数据，即ForpyopenGAN20220103T155713.mat中所有样本都需要，方便后续使用：\n",
    "# 在验证集中，所有前10类数据标注1，42类标注0，代表已知未知类。训练集不必重标注，测试集后续估计有用，这里亦按照此标准重标注\n",
    "# 'tr_X','tr_Y','te_X','te_Y','gte_X','gte_Y'\n",
    "\n",
    "# datas = scio.loadmat('../data/ForpyopenGAN20220103T155713.mat')\n",
    "# datas = scio.loadmat('../data/SignalAcquisitionForpyopenGAN20220223T224326.mat')\n",
    "# s2\n",
    "datas = scio.loadmat('../data/SignalAcquisitionForpyopenGAN20220223T224326.mat')\n",
    "print(datas['tr_X'].shape)\n",
    "Xtrain = np.transpose(datas['tr_X'],[3,2,0,1])\n",
    "Xtest = np.transpose(datas['te_X'],[3,2,0,1])\n",
    "Xval = np.transpose(datas['gte_X'],[3,2,0,1])\n",
    "# Xdtest = np.transpose(datas['dte_X'],[3,2,0,1])\n",
    "print(Xtrain.shape,'\\n',Xtest.shape,'\\n',\\\n",
    "    Xval.shape,'\\n')\n",
    "# 标签\n",
    "# print(datas1[0,0,:,:])\n",
    "Ytrain = datas['tr_Y']\n",
    "Ytest = datas['te_Y']\n",
    "Yval = datas['gte_Y']\n",
    "# Ydtest = datas['dte_Y']\n",
    "print(Ytrain.shape,'\\n',Ytest.shape,'\\n',\\\n",
    "    Yval.shape,'\\n')\n",
    "print(Ytrain.shape,'\\n',len(Ytrain),Ytrain[1,0])\n",
    "# print(len(datalb))\n",
    "# print(datas1[0,0,:,:])\n",
    "\n",
    "# print(datas['Y_TrainP'].ndim)\n",
    "# datalb = datas['Y_TrainP']\n",
    "# print(len(datalb))\n",
    "# print(datalb[1,0])\n",
    "# emg1 = datalb[1,0]\n",
    "# type(emg1)\n",
    "# emg1.astype(np.float32)\n",
    "# np.save('../data/trainY.npy',datalb)\n",
    "# print(datalb[1,0])\n",
    "dataset = {}\n",
    "dataset['Ytrain'] = Ytrain\n",
    "dataset['Xtrain'] = Xtrain\n",
    "dataset['Xtest'] = Xtest\n",
    "dataset['Ytest'] = Ytest\n",
    "dataset['Xval'] = Xval\n",
    "dataset['Yval'] = Yval\n",
    "# dataset['Xdtest'] = Xdtest\n",
    "# dataset['Ydtest'] = Ydtest\n",
    "np.save('../data/OpenganDataSet_220611a_0611.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 32, 20, 10]             320\n",
      "            Conv2d-2            [1, 32, 20, 10]           9,248\n",
      "            Linear-3                   [1, 128]         819,328\n",
      "         Dropout2d-4                   [1, 128]               0\n",
      "            Linear-5                    [1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 830,186\n",
      "Trainable params: 830,186\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 3.17\n",
      "Estimated Total Size (MB): 3.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#coding=utf8\n",
    "# import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import scipy.io as scio\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "import datetime\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from utils.networks import *\n",
    "from utils.reuse import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 自定义数据集类\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "])\n",
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=0\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=32 * 10 * 20, out_features=128)\n",
    "        self.out = nn.Linear(in_features=128, out_features=10)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 32 * 10 * 20)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dr1(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "class EMGDataset(Dataset):\n",
    " \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transforms = transforms.ToTensor()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        emgData = self.data[index,:,:,:]\n",
    "        emgData = np.squeeze(emgData)#似乎不应该压缩了\n",
    "        emglabel = self.label[index]\n",
    "        emglabel = emglabel.astype(np.int16)\n",
    "        emgData = self.transforms(emgData)      \n",
    "        \n",
    "        return emgData,emglabel\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "net = Network()\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "summary(net, (1, 20, 10), batch_size=1, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集制作\n",
    "# 这里直接用了前面的mat引出的变量，所以没有重新加载数据，直接把前面的代码运行一下就行了\n",
    "# known class for CNN and GAN \n",
    "train_set_kn = EMGDataset(ktr_X,ktr_Y)\n",
    "test_set_kn = EMGDataset(kte_X,kte_Y)\n",
    "# valiate class as openset for GAN Discriminator,\n",
    "# last number means the count of class\n",
    "val_Y_5c = val_Y_5c[:,0]\n",
    "val_Y_10c =val_Y_10c[:,0]\n",
    "val_Y_15c = val_Y_15c[:,0]\n",
    "val_Y_20c = val_Y_20c[:,0]\n",
    "val_Y_30c = val_Y_30c[:,0]\n",
    "val_Y_42c = val_Y_42c[:,0]\n",
    "\n",
    "val_set_5c = EMGDataset(val_X_5c,val_Y_5c)\n",
    "val_set_10c = EMGDataset(val_X_10c,val_Y_10c)\n",
    "val_set_15C = EMGDataset(val_X_15c,val_Y_15c)\n",
    "val_set_20c = EMGDataset(val_X_20c,val_Y_20c)\n",
    "val_set_30c = EMGDataset(val_X_30c,val_Y_30c)\n",
    "val_set_42c = EMGDataset(val_X_42c,val_Y_42c)\n",
    "# dtest,a larger val set, AKA openset\n",
    "dte_Y_5c = dte_Y_5c[:,0]\n",
    "dte_Y_10c = dte_Y_10c[:,0]\n",
    "dte_Y_15c = dte_Y_15c[:,0]\n",
    "dte_Y_20c = dte_Y_20c[:,0]\n",
    "dte_Y_30c = dte_Y_30c[:,0]\n",
    "dte_Y_42c = dte_Y_42c[:,0]\n",
    "\n",
    "op_set_5c = EMGDataset(dte_X_5c,dte_Y_5c)\n",
    "op_set_10c = EMGDataset(dte_X_10c,dte_Y_10c)\n",
    "op_set_15c = EMGDataset(dte_X_15c,dte_Y_15c)\n",
    "op_set_20c = EMGDataset(dte_X_20c,dte_Y_20c)\n",
    "op_set_30c = EMGDataset(dte_X_30c,dte_Y_30c)\n",
    "op_set_42c = EMGDataset(dte_X_42c,dte_Y_42c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 计算数据集的网络预测输出并构建新的特征向量四维 array\n",
    "# 注意迭代器只能建立一次，然后以此前进，所以这里单列一行，避免重复建设\n",
    "# 达成类似目标的做法有很多种，例如 append() 等，这里先完成功能，优化待后来同学了\n",
    "\n",
    "def emgdata_to_net_preds(data_set,net_vector):\n",
    "    batchl = iter(data_set)\n",
    "    emg_vec = [torch.tensor([],requires_grad=False) for i in range(len(data_set.label))]\n",
    "    for idx, _ in enumerate(emg_vec):\n",
    "        sample_data,sample_label = next(batchl)\n",
    "        sample_data = sample_data.to(torch.float32).unsqueeze(0)\n",
    "        sample_label = torch.as_tensor(sample_label).long()\n",
    "        emg_vec[idx] = net_vector(sample_data).detach().numpy()\n",
    "    emg_vec_np = np.array(emg_vec)\n",
    "    emg_vec_np = emg_vec_np[:,np.newaxis,:,:]\n",
    "    return emg_vec_np\n",
    "# 使用训练好的模型，用其输出构建新数据集\n",
    "# 这段感觉应该放在数据处理的，但好像不是那么好切割开，就先这样吧\n",
    "checkpoint_for_vector = torch.load('..\\model\\opg_testops_220705a\\s5\\c_final_acc9421_2022_07_06_00_27_22.pth')\n",
    "net_vector = Network()\n",
    "net_vector.load_state_dict(checkpoint_for_vector)\n",
    "net_vector.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emg_vec_ktr_X = emgdata_to_net_preds(data_set=train_set_kn, net_vector = net_vector)\n",
    "emg_vec_kte_X = emgdata_to_net_preds(data_set=test_set_kn, net_vector = net_vector)\n",
    "\n",
    "emg_vec_val_X_5c = emgdata_to_net_preds(data_set=val_set_5c, net_vector = net_vector)\n",
    "emg_vec_val_X_10c = emgdata_to_net_preds(data_set=val_set_10c, net_vector = net_vector)\n",
    "emg_vec_val_X_15c = emgdata_to_net_preds(data_set=val_set_15C, net_vector = net_vector)\n",
    "emg_vec_val_X_20c = emgdata_to_net_preds(data_set=val_set_20c, net_vector = net_vector)\n",
    "emg_vec_val_X_30c = emgdata_to_net_preds(data_set=val_set_30c, net_vector = net_vector)\n",
    "emg_vec_val_X_42c = emgdata_to_net_preds(data_set=val_set_42c, net_vector = net_vector)\n",
    "\n",
    "emg_vec_dte_X_5c = emgdata_to_net_preds(data_set=op_set_5c, net_vector = net_vector)\n",
    "emg_vec_dte_X_10c = emgdata_to_net_preds(data_set=op_set_10c, net_vector = net_vector)\n",
    "emg_vec_dte_X_15c = emgdata_to_net_preds(data_set=op_set_15c, net_vector = net_vector)\n",
    "emg_vec_dte_X_20c = emgdata_to_net_preds(data_set=op_set_20c, net_vector = net_vector)\n",
    "emg_vec_dte_X_30c = emgdata_to_net_preds(data_set=op_set_30c, net_vector = net_vector)\n",
    "emg_vec_dte_X_42c = emgdata_to_net_preds(data_set=op_set_42c, net_vector = net_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 详细说明见 utils/dataprocess.py\n",
    "# 为什么这个函数会把原始的dataset_Y值也改变了？\n",
    "def emgdata_label_tsp_01_v2(dataset_Y,num_knclass):\n",
    "    emg_label = dataset_Y\n",
    "    new_label = []\n",
    "    new_label = emg_label\n",
    "    kn_idx = (new_label < num_knclass)\n",
    "    kn_idx = kn_idx.squeeze()\n",
    "    un_idx = (new_label >= num_knclass)\n",
    "    un_idx = un_idx.squeeze()\n",
    "    new_label[kn_idx] = 1\n",
    "    new_label[un_idx] = 0\n",
    "    return new_label\n",
    "# 为什么只是让标签变成01，名字中也带 vec 呢（vec是指网络输出后的向量），\n",
    "# 我只是想让他们处于一个批次，这样一加载 vec x（显然只有训练GAN 才用得上），\n",
    "# 就想起来得加载 vec_y\n",
    "emg_vec_val_Y_5c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_5c, num_knclass=10)\n",
    "emg_vec_val_Y_10c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_10c, num_knclass=10)\n",
    "emg_vec_val_Y_15c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_15c, num_knclass=10)\n",
    "emg_vec_val_Y_20c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_20c, num_knclass=10)\n",
    "emg_vec_val_Y_30c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_30c, num_knclass=10)\n",
    "emg_vec_val_Y_42c = emgdata_label_tsp_01_v2(dataset_Y=val_Y_42c, num_knclass=10)\n",
    "\n",
    "emg_vec_dte_Y_5c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_5c, num_knclass=10)\n",
    "emg_vec_dte_Y_10c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_10c, num_knclass=10)\n",
    "emg_vec_dte_Y_15c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_15c, num_knclass=10)\n",
    "emg_vec_dte_Y_20c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_20c, num_knclass=10)\n",
    "emg_vec_dte_Y_30c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_30c, num_knclass=10)\n",
    "emg_vec_dte_Y_42c = emgdata_label_tsp_01_v2(dataset_Y=dte_Y_42c, num_knclass=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/SignalAcquisitionForpyopenGAN20220223T224326.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cwdbo\\anaconda3\\envs\\torchlearn\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/SignalAcquisitionForpyopenGAN20220223T224326.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e355d5b6a776>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdatas_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/SignalAcquisitionForpyopenGAN20220223T224326.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mktr_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatas_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ktr_Y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mkte_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatas_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kte_Y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cwdbo\\anaconda3\\envs\\torchlearn\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \"\"\"\n\u001b[0;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cwdbo\\anaconda3\\envs\\torchlearn\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cwdbo\\anaconda3\\envs\\torchlearn\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cwdbo\\anaconda3\\envs\\torchlearn\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/SignalAcquisitionForpyopenGAN20220223T224326.mat'"
     ]
    }
   ],
   "source": [
    "# 现在组合数据集，合到dataset这个dict 就够了，没必要新建变量\n",
    "\n",
    "dataset['ktr_vec_X'] = emg_vec_ktr_X\n",
    "dataset['kte_vec_X'] = emg_vec_kte_X\n",
    "\n",
    "dataset['val_vec_X_5c'] = emg_vec_val_X_5c\n",
    "dataset['val_vec_X_10c'] = emg_vec_val_X_10c\n",
    "dataset['val_vec_X_15c'] = emg_vec_val_X_15c\n",
    "dataset['val_vec_X_20c'] = emg_vec_val_X_20c\n",
    "dataset['val_vec_X_30c'] = emg_vec_val_X_30c\n",
    "dataset['val_vec_X_42c'] = emg_vec_val_X_42c\n",
    "\n",
    "dataset['dte_vec_X_5c'] = emg_vec_dte_X_5c\n",
    "dataset['dte_vec_X_10c'] = emg_vec_dte_X_10c\n",
    "dataset['dte_vec_X_15c'] = emg_vec_dte_X_15c\n",
    "dataset['dte_vec_X_20c'] = emg_vec_dte_X_20c\n",
    "dataset['dte_vec_X_30c'] = emg_vec_dte_X_30c\n",
    "dataset['dte_vec_X_42c'] = emg_vec_dte_X_42c\n",
    "\n",
    "dataset['val_vec_Y_5c'] = emg_vec_val_Y_5c\n",
    "dataset['val_vec_Y_10c'] = emg_vec_val_Y_10c\n",
    "dataset['val_vec_Y_15c'] = emg_vec_val_Y_15c\n",
    "dataset['val_vec_Y_20c'] = emg_vec_val_Y_20c\n",
    "dataset['val_vec_Y_30c'] = emg_vec_val_Y_30c\n",
    "dataset['val_vec_Y_42c'] = emg_vec_val_Y_42c\n",
    "\n",
    "dataset['dte_vec_Y_5c'] = emg_vec_dte_Y_5c\n",
    "dataset['dte_vec_Y_10c'] = emg_vec_dte_Y_10c\n",
    "dataset['dte_vec_Y_15c'] = emg_vec_dte_Y_15c\n",
    "dataset['dte_vec_Y_20c'] = emg_vec_dte_Y_20c\n",
    "dataset['dte_vec_Y_30c'] = emg_vec_dte_Y_30c\n",
    "dataset['dte_vec_Y_42c'] = emg_vec_dte_Y_42c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(\"../../data/nina_db1/s5/Fopg_s5_t04_multiset_20220703_vec.npy\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emgdata_label_tsp_01(dataset,num_knclass):\n",
    "    emg_vec = []\n",
    "    batch = iter(dataset)\n",
    "    for _, label in batch:\n",
    "        if label<num_knclass:\n",
    "            emg_vec.append(1)\n",
    "        else:\n",
    "            emg_vec.append(0)\n",
    "    return emg_vec\n",
    "\n",
    "emg_vec_val_lb = emgdata_label_tsp_01(dataset = val_set,num_knclass=10)\n",
    "emg_vec_dte_lb = emgdata_label_tsp_01(dataset = val_set,num_knclass=10)\n",
    "emg_vec_te_lb = emgdata_label_tsp_01(dataset = val_set,num_knclass=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opg_fea_full = {}\n",
    "# opg_fea_full['Ytrain'] = Ytrain\n",
    "# opg_fea_full['Xtrain'] = emg_vec_npp_tr\n",
    "# opg_fea_full['Xtest'] = emg_vec_npp_te\n",
    "# opg_fea_full['Ytest'] = Ytest\n",
    "# opg_fea_full['Xval'] = emg_vec_npp_val\n",
    "# opg_fea_full['Yval'] = Yval\n",
    "# opg_fea_full['Xdtest'] = emg_vec_npp_teg\n",
    "# opg_fea_full['Ydtest'] = Ydtest\n",
    "\n",
    "# opg_fea_full['Yd_nlb'] = emg_vec_dte_lb\n",
    "# opg_fea_full['val_nlb'] = emg_vec_val_lb\n",
    "# opg_fea_full['Yte_nlb'] = emg_vec_te_lb\n",
    "# np.save('../data/OpenganDatafea_full_2222.npy',opg_fea_full)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也许会用到的一些备用代码\n",
    "# # EMG需要转化成6维特征，用到刚刚训练的模型\n",
    "# checkpoint_net_fe = torch.load('.//ckp//opg_0217a//oth//c_ep_200_acc9763_2022_02_26_23_18_44.pth')\n",
    "# net_fe = Network_CNN_6ch_6cls_smr_v1()\n",
    "# net_fe.load_state_dict(checkpoint_net_fe['model'])\n",
    "# net_fe.eval()\n",
    "# emg_vec_npp_tr = emgdata_to_net_preds(data_set=train_set, net_vector = net_fe)\n",
    "# emg_vec_npp_te = emgdata_to_net_preds(data_set=test_set, net_vector = net_fe)\n",
    "# emg_vec_npp_val = emgdata_to_net_preds(data_set=val_set, net_vector = net_fe)\n",
    "# # 特征重组为新的数据集\n",
    "# opg_fea_full = {}\n",
    "# opg_fea_full['Ytrain'] = CNNdataset['Ytrain']\n",
    "# opg_fea_full['Xtrain'] = emg_vec_npp_tr\n",
    "# opg_fea_full['Xtest'] = emg_vec_npp_te\n",
    "# opg_fea_full['Ytest'] = CNNdataset['Ytest']\n",
    "# opg_fea_full['Xval'] = emg_vec_npp_val\n",
    "# opg_fea_full['Yval'] = CNNdataset['Yval']\n",
    "# np.save('../data/OpenganDatafea_smr_10cl_220227.npy',opg_fea_full)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也许会用到的一些备用代码\n",
    "# 1Ytrain-20210721T193346.mat\n",
    "\n",
    "# datas = scio.loadmat('../data/Y_TrainP.mat')\n",
    "# print(datas['Y_TrainP'].ndim)\n",
    "# datalb = datas['Y_TrainP']\n",
    "# print(len(datalb))\n",
    "# print(datalb[1,0])\n",
    "# emg1 = datalb[1,0]\n",
    "# type(emg1)\n",
    "# emg1.astype(np.float32)\n",
    "# np.save('../data/trainY.npy',datalb)\n",
    "# print(datalb[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里检查了数据形状与维度，训练时不需要，注掉了\n",
    "\n",
    "# tx = np.load('../data/trainX.npy')\n",
    "# txp = tx[1,:,:,:]\n",
    "# print(txp.shape)\n",
    "# print(np.squeeze(txp).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "220521,组建包含所有需要数据（原始样本，CNN特征输出，手势动作标签，已知未知类标签）的大数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 220521,组建包含所有需要数据（原始样本，CNN特征输出，手势动作标签，已知未知类标签）的大数据集\n",
    "# 加载原始数据集\n",
    "# datas = scio.loadmat(\"../data/SignalAcqForpyopenGAN20220520T165247.mat\")\n",
    "\n",
    "datas = scio.loadmat(\"../data/SignalAcqForpyopenGAN20220522T091046.mat\")\n",
    "# 后缀 known 是只含已知类的数据集，opset 表示既有已知也有未知，这里测试集known是验证集opset的子集，取了前六个已知类\n",
    "Xtrain_known = np.transpose(datas[\"tr_X\"], [3, 2, 0, 1])\n",
    "Xtest_known = np.transpose(datas[\"te_X\"], [3, 2, 0, 1])\n",
    "Xval_opset = np.transpose(datas[\"gte_X\"], [3, 2, 0, 1])\n",
    "Ytrain_known = datas[\"tr_Y\"]\n",
    "Ytest_known = datas[\"te_Y\"]\n",
    "Yval_opset = datas[\"gte_Y\"]\n",
    "# mtv 表示真实动作标签，上面的opset 只是指示开闭的01值\n",
    "Yval_opset_mtv = datas[\"gte_YT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# 加载CNN输出特征集，这个集只是将 X train，test,val 过了 CNN 之后变成特征值，所以这里实际上也只需要这些\n",
    "GAN_dataarray = np.load(\"../data/OpenganDatafea_smr_10cl_220227.npy\", allow_pickle=True)\n",
    "GANdataset = GAN_dataarray.item()\n",
    "print(type(GANdataset))\n",
    "X_train_Net_output = GANdataset[\"Xtrain\"]\n",
    "# trainlabel = GANdataset[\"Ytrain\"]\n",
    "X_test_Net_output = GANdataset['Xtest']\n",
    "# testlabel = GANdataset['Ytest']\n",
    "X_val_Net_output = GANdataset[\"Xval\"]\n",
    "# vallabel = GANdataset[\"Yval\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在组合数据集\n",
    "opg_fea_full = {}\n",
    "opg_fea_full[\"Xtrain_known\"] = Xtrain_known\n",
    "opg_fea_full[\"Xtest_known\"] = Xtest_known\n",
    "opg_fea_full[\"Xval_opset\"] = Xval_opset\n",
    "opg_fea_full[\"Ytrain_known\"] = Ytrain_known\n",
    "opg_fea_full[\"Ytest_known\"] = Ytest_known\n",
    "opg_fea_full[\"Yval_opset\"] = Yval_opset\n",
    "\n",
    "opg_fea_full[\"X_train_Net_output\"] = X_train_Net_output\n",
    "opg_fea_full[\"X_test_Net_output\"] = X_test_Net_output\n",
    "opg_fea_full[\"X_val_Net_output\"] = X_val_Net_output\n",
    "\n",
    "opg_fea_full[\"Yval_opset_mtv\"] = Yval_opset_mtv\n",
    "np.save(\"../data/OpgData_full_smr_10cl_220522_2.npy\", opg_fea_full)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "696bc8a05a1eb808e62d18e9328544428937c8e11a4c703581cc2236b7d3d24e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('torchlearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
